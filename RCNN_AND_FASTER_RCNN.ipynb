{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RCNN\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "cdF1itwrIqK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. What are the objectives of using Selective Search in R-CNN."
      ],
      "metadata": {
        "id": "CNJkpFc4IsU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "R CNN means Region Convolutional Neural Network, which is proposed to make the cnn more efficient and advanced for object detection. RCNN is basically comes with the idea of region proposals.Our object detection system consists of three modules.\n",
        "\n",
        "The first generates category-independent region proposals. These proposals define the set of candidate detections available to our detector. The second module is a large convolutional neural network that extracts a fixed-length feature vector from each region. The third module is a set of classspecific linear SVMs.\n",
        "\n",
        "In the RCNN selective search has been taken in use rather the exhaustive search.Becuase Selective Search uses a hierarchical segmentation algorithm to identify potential object boundaries at multiple scales and locations.This selective search find the objects in the image and boundried these objects with boundry boxes.It will reduce the computetional cost and make the process faster.Selective Search aims to generate diverse and meaningful region proposals, increasing the chances of capturing objects of interest. This helps improve the accuracy of the object detection model."
      ],
      "metadata": {
        "id": "Scy-DA-GIsWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explain the following phases involved in R-CNN\n",
        "\n",
        "1. Region Proposal\n",
        "2. Wraping and Resizing\n",
        "3. Pre Trained CNN architecture\n",
        "4. Pre Trained SVM model\n",
        "5. Clean up\n"
      ],
      "metadata": {
        "id": "RZYXWMloIsZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Region Proposal**\n",
        "\n",
        "Region proposal is point out the objects in the images by the bounded boxes . There are sevral type of regoin proposals as as exhustive search,objectness,CPMC ..etc. But in this particular R-Cnn architecture we used the selective search, as because of importance of the context.\n",
        "\n",
        "**Wraping and Resizing :**\n",
        "\n",
        "We extract a 4096-dimensional feature vector from each region proposal. Features are computed by forward propagating\n",
        "a mean-subtracted 227 × 227 RGB image through five convolutional layers and two fully connected layers.In order to compute features for a region proposal, we must first convert the image data in that region into a form that is compatible with the CNN. its architecture requires inputs of a fixed 227 × 227 pixel size.Regardless of the size or aspect ratio of the candidate region, we warp all pixels in a tight bounding box around it to the required size. Prior to warping, we dilate the tight bounding box so that at the warped size there are exactly p pixels of warped image context around the original box.\n",
        "\n",
        "**Pre Trained CNN architecture :**\n",
        "\n",
        "At test time, we run selective search on the test image to extract around 2000 region proposals. We warp each proposal and forward propagate it through the CNN in order to compute features.We can VGG net or resnet for this computetion . This backbone is responsible for learning hierarchical features from the input image.\n",
        "\n",
        "**Pre Trained SVM model :**\n",
        "\n",
        "Then, for each class, we score each extracted feature vector using the SVM trained for that class.\n",
        "\n",
        "**Clean Up :**\n",
        "\n",
        "Given all scored regions in an image, we apply a greedy non-maximum suppression (for each class independently) that rejects a region if it has an intersection-overunion (IoU) overlap with a higher scoring selected region larger than a learned threshold.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZCgl17oSIsbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. What are the possible pre trained CNNs we can use in Pre trained CNN architecture ?\n"
      ],
      "metadata": {
        "id": "q9DVtoNhKZzc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use VGG net, Resnet , inception net and mobile net in the pre trained CNN architecture for compute the features of input image or for the aggrigation of the features of input image."
      ],
      "metadata": {
        "id": "o-P0Fn9fKZ1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How is SVm implemented in the R-CNN Framework ?\n",
        "\n"
      ],
      "metadata": {
        "id": "jF2cxkDIKZ5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of R CNN svm are mostly used for the cleanup of the data. As when the data has come after the feature extraction, it will goes to the svm model, where it will classified in two categories , such as positive and negative. Those who are truely predicted are comes in the postive with value 1 and rest are going to negative with the value of 0. This is how svm is distiniguishes between backgrounds and objects in a image."
      ],
      "metadata": {
        "id": "84KrDeLFKZ7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How does non-maximum Suppression works ?"
      ],
      "metadata": {
        "id": "lhDDonX0NaxZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non-maximum suppression is a post-processing technique. Which is used to detect the final boundry box for an object of the image. As we know that there are seral boundry boxes overlaps in a object in order to indentify the real and whole size of object. In such a case it is crucial to identify that which boundry box is most perfect according to the size of object in the image. So in such a case we define non-maximum suppression which is used to idenify the most preffrable boundry box for an image on the basis of it's confidence lable vlaue , which is decided by IoU (Intersection over union). Which boundry box has the larger value of the confidence lable is considered to the real boundry box for an object in a image."
      ],
      "metadata": {
        "id": "AgmR-OO3NlH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How Fast R-Cnn is better than R-CNN."
      ],
      "metadata": {
        "id": "XpHyiJKYNk_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fast RCNN is an advancement of the R-CNN. as it's training time speed is 8.8x where's RCNN is only 1x . RCNN test time per image is 47 second, where's in RCNN , a image is tested in only 0.32 seconds.\n",
        "\n",
        "Faster R-CNN combined both selective search and object  classification in one.This leads to the a faster archetucture.\n",
        "There are some changement and some extra features has been added in the R-CNN to make it more fast.\n",
        "\n",
        "- Subsampling\n",
        "- ROI Pooling\n",
        "- ROI Projection\n",
        "\n",
        "are some new concept which are proposed for the Faster Rcnn.\n",
        "\n",
        "Subsampling is reducses the size of feature map, so that objects are become compatible to be idenified in the image.and then by the ROI projection the projection of objects in the image has been done. Roi pooling is used to convert the image into 7*7 which is the input size requirment of the fast R-CNN"
      ],
      "metadata": {
        "id": "zKLSSrrHNkm2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In comparison with R-CNN, why did the object classifier activation function change in Fast R-CNN ?"
      ],
      "metadata": {
        "id": "mGduK8U1KIBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the Fast RCNN , at the post processing we are used the softmax activation function. Which is a another modification from R-CNN to fast Rcnn. These softmax function as provide us the probabilty of the classes and also it is computetional low cost. The softmax activation function is differentiable, allowing for efficient gradient propagation during training. This is crucial for training deep neural networks using gradient-based optimization algorithms. SVMs, being non-differentiable, required approximations or two-step training, making the optimization process less straightforward."
      ],
      "metadata": {
        "id": "Ebzw9wTwKH9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  What major changes in Faster R-Cnn compared to Fast R-CNN ?"
      ],
      "metadata": {
        "id": "bwMMKxx2KH7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Faster R-CNN is an advancment of Fast R-CNN. It is more faster and efficient than both R-CNN and Fast R-RCNN. It is combination of Regoin proposed network and fast RCNN. It test one image with proposal in 0.2 second , while fast RCNN takes 2 second for the same opration and even RCNN takes 50 sec for this.So it is very fast. Some of the changes of Faster R-CNN from fast- RCNN are below;\n",
        "\n",
        "- Selective search <----Replaced by----> Reason Proposal Network.\n",
        "- Introducing the concept of ancor boxes\n",
        "\n",
        " Instead of relying on an external region proposal method (like Selective Search in Fast R-CNN), the RPN generates region proposals as an integral part of the network. This eliminates the need for a separate region proposal step, making the entire object detection pipeline end-to-end trainable.\n",
        "\n",
        " Faster R-CNN introduces anchor box regression to refine the location of anchor boxes during training. This contributes to better localization accuracy for object detection. In faster RCNN 9 anchor boxes are used.\n"
      ],
      "metadata": {
        "id": "SaCbisnnKH4U"
      }
    }
  ]
}